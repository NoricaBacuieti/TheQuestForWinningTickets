{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Installing packages"
      ],
      "metadata": {
        "id": "-0AZC1JkodWo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b_NClEn2y-EJ"
      },
      "outputs": [],
      "source": [
        "!pip install lime\n",
        "!pip install gdown\n",
        "!pip install -q pandas\n",
        "!pip install --user -q torch\n",
        "!pip install -q transformers\n",
        "!pip install --user -q pytest \n",
        "!pip install --user -q tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Warning***: Depending on the runtime used, you might have to restart the kernel in order for the new libraries to be located properly."
      ],
      "metadata": {
        "id": "KIvaO-UFlMPo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries"
      ],
      "metadata": {
        "id": "lLCDt-bPk_mL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ypPZEY9BuckP"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "import warnings\n",
        "import sklearn.datasets\n",
        "import sklearn.ensemble\n",
        "import numpy as np\n",
        "import lime.submodular_pick\n",
        "import lime.lime_tabular\n",
        "import gdown\n",
        "import itertools\n",
        "import functools as fu\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import h5py\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import torch\n",
        "import transformers\n",
        "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
        "from transformers import AutoModel, AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YYrc0_7kKfpr"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.layers import Dense, Conv1D, Input, Reshape, Permute, Add, Flatten, BatchNormalization, Activation, MaxPooling1D, Concatenate,Dropout, AveragePooling1D, GlobalAveragePooling1D, GlobalMaxPooling1D, UpSampling1D\n",
        "from keras.regularizers import l2, l1, l1_l2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define the number of GPU's and batch size you can support\n"
      ],
      "metadata": {
        "id": "y33-CHc3nPAQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mwgRzrXrrirc"
      },
      "outputs": [],
      "source": [
        "max_length = 512\n",
        "num_gpu = 1\n",
        "batch_size = 30 * num_gpu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_DwsHjRy0x7"
      },
      "source": [
        "# Helper functions"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Computing classification probabilities for each class."
      ],
      "metadata": {
        "id": "gxg4NmeDlFvZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "10oWwEx1rire"
      },
      "outputs": [],
      "source": [
        "# Converts logits into probabilities of the tweet belonging to each class \n",
        "def softmax(x):\n",
        "    e_x = np.exp(x - np.max(x))\n",
        "    return e_x / e_x.sum(axis=0) \n",
        "\n",
        "# Get the predicted class for each tweet, along with the probability of it belonging to the predicted class \n",
        "def class_and_confidence(preds):\n",
        "    softmaxes = []\n",
        "    for logits in preds[0]:\n",
        "        sfmax = softmax(logits)\n",
        "        argmax = logits.argmax()\n",
        "        softmaxes.append([argmax, sfmax[argmax]])\n",
        "    return softmaxes"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performing encoding for clean tweets. "
      ],
      "metadata": {
        "id": "Ch5CVhZ5lMeB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxe2BwPTxDYS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
        "\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True)\n",
        "\n",
        "def convert_example_to_feature(review):\n",
        "  return tokenizer.encode_plus(review,\n",
        "                add_special_tokens = True, \n",
        "                max_length = max_length, \n",
        "                pad_to_max_length = True, \n",
        "                return_attention_mask = True, \n",
        "              )\n",
        "  \n",
        "\n",
        "def map_example_to_dict(input_ids, attention_masks, token_type_ids):\n",
        "  return {\n",
        "      \"input_ids\": input_ids,\n",
        "      \"token_type_ids\": token_type_ids,\n",
        "      \"attention_mask\": attention_masks,\n",
        "  }\n",
        "\n",
        "\n",
        "def encode_tweets(ds):\n",
        "   input_ids_list = []\n",
        "   token_type_ids_list = []\n",
        "   attention_mask_list = []\n",
        "   label_list = []\n",
        "   for index, row in tqdm(ds.iterrows()):\n",
        "     bert_input = convert_example_to_feature(row[\"tweet\"])\n",
        "     input_ids_list.append(bert_input['input_ids'])\n",
        "     token_type_ids_list.append(bert_input['token_type_ids'])\n",
        "     attention_mask_list.append(bert_input['attention_mask'])\n",
        "     \n",
        "\n",
        "   return tf.data.Dataset.from_tensor_slices((input_ids_list, attention_mask_list, token_type_ids_list)).map(map_example_to_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PxoPrvanrirg"
      },
      "outputs": [],
      "source": [
        "# Same as above but tailored for feature visuation.\n",
        "\n",
        "def map_tweet_to_dict(input_ids, attention_masks, token_type_ids):\n",
        "  return {\n",
        "      \"input_ids\": input_ids,\n",
        "      \"token_type_ids\": token_type_ids,\n",
        "      \"attention_mask\": attention_masks,\n",
        "  }\n",
        "\n",
        "def encode_tweet(tweet):\n",
        "   input_id = []\n",
        "   token_type_id = []\n",
        "   attention_mask = []\n",
        "   label = []\n",
        "\n",
        "   bert_input = convert_example_to_feature(tweet)\n",
        "   input_id.append(bert_input['input_ids'])\n",
        "   token_type_id.append(bert_input['token_type_ids'])\n",
        "   attention_mask.append(bert_input['attention_mask'])\n",
        "\n",
        "   return tf.data.Dataset.from_tensor_slices((input_id, attention_mask, token_type_id)).map(map_tweet_to_dict)\n",
        "\n",
        "# Predict proba function needed for feature visualizaiton: Gives probabilities for belonging to each of the two classes.\n",
        "def predict_proba(tweets):\n",
        "    result = []\n",
        "    for tweet in tweets:\n",
        "        encoded = encode_tweet(tweet)\n",
        "        batched = encoded.batch(1)\n",
        "        preds = loaded_model.predict(batched)\n",
        "        cls_pred = class_and_confidence(preds)\n",
        "\n",
        "        cls = cls_pred[0][0]\n",
        "        pred = cls_pred[0][1]\n",
        "\n",
        "        if cls == 1:\n",
        "             result.append(np.array([1 - pred,pred]))\n",
        "        else:\n",
        "            result.append(np.array([pred,1 - pred]))\n",
        "\n",
        "            \n",
        "    return np.array(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data generation #\n",
        "Here just 20000 tweets were analyzed due to time constraints and results not much differing. "
      ],
      "metadata": {
        "id": "YFN_uOlRmftD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xplyJsm3rirh"
      },
      "outputs": [],
      "source": [
        "def create_data(fancy_cleaned_tweets):\n",
        "  df = pd.read_csv(fancy_cleaned_tweets, sep=';', header=0)\n",
        "  class_samples = 10000\n",
        "  df2 = df\n",
        "  df2 = pd.concat([df.iloc[:class_samples], df.iloc[-class_samples:]])\n",
        "  df2 = df2.dropna()\n",
        "    \n",
        "  tweets_encoded = encode_tweets(df2)  \n",
        "\n",
        "  return tweets_encoded, list(df2['sentiment']), list(df2['tweet']) \n",
        "\n",
        "def make_train_data():\n",
        "    tweets_encoded, sentiments_list, tweets_list =  create_data(\"tweets_clean_full_min_fancy.csv\")\n",
        "    return tweets_encoded, sentiments_list, tweets_list "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n52w4mkWriri"
      },
      "outputs": [],
      "source": [
        "ds_X_eval, Y_eval, X_eval = make_train_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zt3hr_YbyXuD"
      },
      "source": [
        "# Load trained model #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pjd0u913HZzo"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
        "\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aZHcTur789i0"
      },
      "outputs": [],
      "source": [
        "loaded_model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels = 2)\n",
        "loaded_model.load_weights(\"bert_b30.h5\")\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
        "\n",
        "loaded_model.compile(optimizer=optimizer, loss=loss, metrics=[metric])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rqqvc4Ikz2ko"
      },
      "source": [
        "# Find tweets with best/worst prediction #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nyPAIY31yXuE"
      },
      "outputs": [],
      "source": [
        "# Obtains tweets with best prediction belonging to class 1 and 0, along with their true label and probability of beloning to the true label/class\n",
        "def find_best_preds(trained_model, num_preds):\n",
        "\n",
        "    ds_X_eval, Y_eval, X_eval = make_train_data()\n",
        "    encoded = ds_X_eval.batch(batch_size)\n",
        "    \n",
        "    preds = trained_model.predict(encoded, batch_size)\n",
        "    predictions = class_and_confidence(preds)\n",
        " \n",
        "    stored_0 =[];\n",
        "    stored_1 =[];\n",
        "    \n",
        "\n",
        "    for i in range(len(Y_eval)):\n",
        "\n",
        "        diff = abs(Y_eval[i] - predictions[i][1]);\n",
        "        \n",
        "        #Store the current tweet if its prediction is better than that of the last tweet\n",
        "        if Y_eval[i] ==1 and (len(stored_1)==0 or diff <= stored_1[len(stored_1)-1][1]):\n",
        "            stored_1.append((i, diff, Y_eval[i], predictions[i][1], X_eval[i]));\n",
        "            \n",
        "        if Y_eval[i] ==0 and (len(stored_0)==0 or diff <= stored_0[len(stored_0)-1][1]):\n",
        "            stored_0.append((i, diff, Y_eval[i], predictions[i], X_eval[i]));\n",
        "\n",
        "    return stored_1[-num_preds:], stored_0[-num_preds:];\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kDumbBAByXuE"
      },
      "outputs": [],
      "source": [
        "# Same as above but worst prediction\n",
        "def find_worst_preds(trained_model, num_preds):\n",
        "\n",
        "    ds_X_eval, Y_eval, X_eval = make_train_data()\n",
        "    encoded = ds_X_eval.batch(batch_size)\n",
        "    \n",
        "    preds = trained_model.predict(encoded, batch_size)\n",
        "    predictions = class_and_confidence(preds)\n",
        " \n",
        "    stored_0 =[];\n",
        "    stored_1 =[];\n",
        "    \n",
        "    \n",
        "    for i in range(len(Y_eval)):\n",
        "\n",
        "        diff = abs(Y_eval[i] - predictions[i][1]);\n",
        "\n",
        "        if Y_eval[i] ==1 and (len(stored_1)==0 or diff >= stored_1[len(stored_1)-1][1]):\n",
        "            stored_1.append((i, diff, Y_eval[i], predictions[i][1], X_eval[i]));\n",
        "            \n",
        "        if Y_eval[i] ==0 and (len(stored_0)==0 or diff >= stored_0[len(stored_0)-1][1]):\n",
        "            stored_0.append((i, diff, Y_eval[i], predictions[i], X_eval[i]));\n",
        "\n",
        "    return stored_1[-num_preds:], stored_0[-num_preds:];"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCfnwqovF0Fh"
      },
      "source": [
        "# Obtain the tweets with the best predictions "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xvzRGnffyXuE"
      },
      "outputs": [],
      "source": [
        "#Contain tweets belonging to class 1 and class 0 with best predictions\n",
        "c1, c0 = find_best_preds(loaded_model, 5);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HkPiCEQHc0qe"
      },
      "outputs": [],
      "source": [
        "#Contain tweets belonging to class 1 and class 0 with worst predictions\n",
        "d1, d0 = find_worst_preds(loaded_model, 5);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zK4mM1U1z-dR"
      },
      "source": [
        "# Instantiate the explainer #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-jZ523ViyXuF"
      },
      "outputs": [],
      "source": [
        "from lime import lime_text\n",
        "from lime.lime_text import LimeTextExplainer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from lime.lime_text import IndexedString,IndexedCharacters\n",
        "from lime.lime_base import LimeBase\n",
        "from sklearn.linear_model import Ridge, lars_path\n",
        "from lime.lime_text import explanation\n",
        "from functools import partial\n",
        "import scipy as sp\n",
        "from sklearn.utils import check_random_state\n",
        "\n",
        "explainer = LimeTextExplainer(class_names=[0, 1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykJy_Gp8yXuF"
      },
      "source": [
        "# Compute best/worst explanations for class 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_yGB40XJyXuF"
      },
      "outputs": [],
      "source": [
        "instance = 4;\n",
        "\n",
        "exp = explainer.explain_instance(c1[instance][4], predict_proba, num_features=20, labels=(1,))\n",
        "\n",
        "exp.show_in_notebook(text=True)\n",
        "exp.save_to_file('best_1.html')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "instance = 4;\n",
        "\n",
        "exp = explainer.explain_instance(d1[instance][4], predict_proba, num_features=20, labels=(1,))\n",
        "\n",
        "exp.show_in_notebook(text=True)\n",
        "exp.save_to_file('1_worst_1.html')"
      ],
      "metadata": {
        "id": "zgzJe_GboRv1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPWJmJLCyXuj"
      },
      "source": [
        "# Compute best/worst explanations for class 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HzCbZ2lyyXuj"
      },
      "outputs": [],
      "source": [
        "instance = 4;\n",
        "\n",
        "exp = explainer.explain_instance(c0[instance][4], predict_proba, num_features=20, labels=(0,))\n",
        "\n",
        "exp.show_in_notebook(text=True)\n",
        "exp.save_to_file('0_best_1.html')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "instance = 4;\n",
        "\n",
        "exp = explainer.explain_instance(d0[instance][4], predict_proba, num_features=20, labels=(0,))\n",
        "\n",
        "exp.show_in_notebook(text=True)\n",
        "exp.save_to_file('0_worst_1.html')"
      ],
      "metadata": {
        "id": "DTBnvCjUoWfs"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}